{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Copyright (c) 2015, 2016 [Sebastian Raschka](sebastianraschka.com)\n",
    "[Li-Yi Wei](http://www.liyiwei.org)\n",
    "\n",
    "https://github.com/1iyiwei/pyml\n",
    "\n",
    "[MIT License](https://github.com/1iyiwei/pyml/blob/master/LICENSE.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Python Machine Learning - Code Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 13 - Parallelizing Neural Network Training with Theano\n",
    "\n",
    "We have seen how to write a multi-layer perceptron from scratch.\n",
    "\n",
    "We can also just use existing libraries.\n",
    "* Theano, Torch, TensorFlow, Caffe, etc.\n",
    "\n",
    "Advantages of Theano\n",
    "* Python interface\n",
    "* Platform support\n",
    "* GPU support for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note that the optional watermark extension is a small IPython notebook plugin that I developed to make the code reproducible. You can just skip the following line(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2016-10-10 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.1\n",
      "matplotlib 1.5.1\n",
      "theano 0.8.2\n",
      "keras 1.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a '' -u -d -v -p numpy,matplotlib,theano,keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "*The use of `watermark` is optional. You can install this IPython extension via \"`pip install watermark`\". For more information, please see: https://github.com/rasbt/watermark.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Overview\n",
    "\n",
    "- [Building, compiling, and running expressions with Theano](#Building,-compiling,-and-running-expressions-with-Theano)\n",
    "  - [What is Theano?](#What-is-Theano?)\n",
    "  - [First steps with Theano](#First-steps-with-Theano)\n",
    "  - [Configuring Theano](#Configuring-Theano)\n",
    "  - [Working with array structures](#Working-with-array-structures)\n",
    "  - [Wrapping things up â€“ a linear regression example](#Wrapping-things-up:-A--linear-regression-example)\n",
    "- [Choosing activation functions for feedforward neural networks](#Choosing-activation-functions-for-feedforward-neural-networks)\n",
    "  - [Logistic function recap](#Logistic-function-recap)\n",
    "  - [Estimating probabilities in multi-class classification via the softmax function](#Estimating-probabilities-in-multi-class-classification-via-the-softmax-function)\n",
    "  - [Broadening the output spectrum by using a hyperbolic tangent](#Broadening-the-output-spectrum-by-using-a-hyperbolic-tangent)\n",
    "- [Training neural networks efficiently using Keras](#Training-neural-networks-efficiently-using-Keras)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building, compiling, and running expressions with Theano\n",
    "\n",
    "Developed by the LISA lab lead by Joshua Bengio started in 2008.\n",
    "\n",
    "Harness multi/many-core CPU/GPU without the burden of \n",
    "* parallel computing code\n",
    "* memory management across processors\n",
    "\n",
    "<img src='./images/13_01.png' width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Theano?\n",
    "\n",
    "A machine learning library with interface in Python.\n",
    "* with more speed/memory optimization\n",
    "\n",
    "Focus on tensors as the core data structure.\n",
    "\n",
    "Tensors are multi-dimensional arrays.\n",
    "* rank 0 for scalars\n",
    "* rank 1 for vectors\n",
    "* rank 2 for matrices\n",
    "\n",
    "Symbolic manipulation\n",
    "* build computation graphs\n",
    "* automatic and symbolic differentiation\n",
    "* send compiled expressions/graphs to CPU/GPU for execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First steps with Theano\n",
    "\n",
    "http://deeplearning.net/software/theano/introduction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Depending on your system setup, it is typically sufficient to install Theano via\n",
    "\n",
    "    pip install Theano\n",
    "    \n",
    "For more help with the installation, please see: http://deeplearning.net/software/theano/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Introducing the TensorType variables. For a complete list, see http://deeplearning.net/software/theano/library/tensor/basic.html#all-fully-typed-constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(2.5, dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define expression\n",
    "# which can be visualized as a graph\n",
    "x1 = T.scalar()\n",
    "w1 = T.scalar()\n",
    "w0 = T.scalar()\n",
    "z1 = w1 * x1 + w0\n",
    "\n",
    "# compile\n",
    "net_input = theano.function(inputs=[w1, x1, w0], outputs=z1)\n",
    "\n",
    "# execute\n",
    "answer = net_input(2.0, 1.0, 0.5)\n",
    "print(answer)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11.  17.]\n",
      "[ 12.  18.]\n"
     ]
    }
   ],
   "source": [
    "# define\n",
    "b = T.scalar('b')\n",
    "x = T.vector('x')\n",
    "W = T.matrix('W')\n",
    "\n",
    "y = x.dot(W.transpose())\n",
    "z = W.dot(x) + b\n",
    "\n",
    "# similar to python function\n",
    "# theano function can return multiple outputs\n",
    "f = theano.function(inputs = [x, W, b], outputs = [y, z])\n",
    "\n",
    "output_y, output_z = f([1, 2], [[3, 4], [5, 6]], 1)\n",
    "# output_y, output_z = f([[1, 2]], [[3, 4]], 1) # won't work as x is a vector not matrix\n",
    "# output_y, output_z = f([1, 2], [3, 4], 1) # won't work as W is a matrix not vector\n",
    "# output_y, output_z = f([1, 2], [[3, 4]], [1]) # won't work as b is a scalar not a vector/matrix\n",
    "\n",
    "print(output_y)\n",
    "print(output_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Steps for using Theano:\n",
    "* define symbols and functions\n",
    "* compile the code\n",
    "* execute the code\n",
    "\n",
    "Each variable has a specific type (dtype)\n",
    "* trade-off between accuracy and cost (speed and storage)\n",
    "* we have to choose; good for control, bad as burden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Configuring Theano\n",
    "\n",
    "Processors:\n",
    "- Modern CPUs support 64-bit memory address.\n",
    "- GPUs (and old CPUs) remain in 32-bit.\n",
    "\n",
    "Theano supports both 32 and 64 bits.\n",
    "\n",
    "We can configure Theano to use either: float32 (for 32-bit processors) or float64 (for 64-bit processors).\n",
    "\n",
    "For more options, see\n",
    "- http://deeplearning.net/software/theano/library/config.html\n",
    "- http://deeplearning.net/software/theano/library/floatX.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "# default configuration\n",
    "print(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# we can change it like this\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To change the float type globally, execute \n",
    "\n",
    "    export THEANO_FLAGS=floatX=float32 \n",
    "    \n",
    "in your bash shell. Or execute Python script as\n",
    "\n",
    "    THEANO_FLAGS=floatX=float32 python your_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Running Theano on GPU(s). For prerequisites, please see: http://deeplearning.net/software/theano/tutorial/using_gpu.html\n",
    "\n",
    "Note that `float32` is recommended for GPUs; `float64` on GPUs is currently still relatively slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(theano.config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can run a Python script on CPU (e.g. for prototyping and debug) via:\n",
    "\n",
    "    THEANO_FLAGS=device=cpu,floatX=float64 python your_script.py\n",
    "\n",
    "or GPU (e.g. for real computation) via:\n",
    "\n",
    "    THEANO_FLAGS=device=gpu,floatX=float32 python your_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "It may also be convenient to create a `.theanorc` file in your home directory to make those configurations permanent. For example, to always use `float32`, execute\n",
    "\n",
    "    echo -e \"\\n[global]\\nfloatX=float32\\n\" >> ~/.theanorc\n",
    "    \n",
    "Or, create a `.theanorc` file manually with the following contents\n",
    "\n",
    "    [global]\n",
    "    floatX = float32\n",
    "    device = gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with array structures\n",
    "\n",
    "This is an example code to work with tensors.\n",
    "\n",
    "Create a $2 \\times 3$ tensor, and calculate its column sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column sum: [ 2.  4.  6.]\n",
      "Column sum: [ 2.  4.  6.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define\n",
    "# if you are running Theano on 64 bit mode, \n",
    "# you need to use dmatrix instead of fmatrix\n",
    "x = T.matrix(name='x') # tensor with arbitrary shape\n",
    "x_sum = T.sum(x, axis=0)\n",
    "\n",
    "# compile\n",
    "calc_sum = theano.function(inputs=[x], outputs=x_sum)\n",
    "\n",
    "# execute (Python list)\n",
    "ary = [[1, 2, 3], [1, 2, 3]]\n",
    "print('Column sum:', calc_sum(ary))\n",
    "\n",
    "# execute (NumPy array)\n",
    "ary = np.array(ary, dtype=theano.config.floatX)\n",
    "print('Column sum:', calc_sum(ary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "<TensorType(float32, matrix)>\n",
      "<TensorType(float32, matrix)>\n"
     ]
    }
   ],
   "source": [
    "# name can help debug\n",
    "y = T.matrix(name='hello')\n",
    "z = T.matrix()\n",
    "\n",
    "print(y) # will print out variable name\n",
    "print(z) # will print out variable type\n",
    "print(y.type()) # will print out type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorType(float32, matrix)>\n",
      "<TensorType(float64, matrix)>\n"
     ]
    }
   ],
   "source": [
    "# explicit type specification\n",
    "wf = T.fmatrix(name='wfmatrix')\n",
    "wd = T.dmatrix(name='wdmatrix')\n",
    "\n",
    "print(wf.type())\n",
    "print(wd.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory management\n",
    "\n",
    "### shared \n",
    "\n",
    "Variable with storage that is shared between functions that it appears in. \n",
    "* can have initial or constant values, e.g. weights of a neural network\n",
    "* retain value across function calls\n",
    "* cannot be used as input to a function\n",
    "* can be updated after each function call\n",
    "\n",
    "Can be more efficient than input variable\n",
    "* update in place instead of transferring around\n",
    "* Theano can then optimize the storage across CPUs and GPUs\n",
    "\n",
    "More info about memory management in Theano can be found under:\n",
    "* http://deeplearning.net/software/theano/tutorial/aliasing.html\n",
    "* https://www.quora.com/What-is-the-meaning-and-benefit-of-shared-variables-in-Theano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z0: [[ 1.]]\n",
      "z1: [[ 7.]]\n",
      "z2: [[ 13.]]\n",
      "z3: [[ 19.]]\n",
      "z4: [[ 25.]]\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "x = T.matrix(name='x')\n",
    "b = theano.shared(np.asarray([[1]], dtype=theano.config.floatX), name='b')\n",
    "w = theano.shared(np.asarray([[0.0, 0.0, 0.0]], \n",
    "                             dtype=theano.config.floatX))\n",
    "\n",
    "# w = w + 1.0 # this will cause error\n",
    "z = x.dot(w.T) + b\n",
    "\n",
    "update = [[w, w + 1.0]] # update w after each function call\n",
    "\n",
    "# compile\n",
    "f = theano.function(inputs=[x],\n",
    "                    updates=update,\n",
    "                    outputs=z)\n",
    "\n",
    "# won't compile as shared variable cannot be used as input\n",
    "# g = theano.function(inputs=[x, b], outputs = z)\n",
    "\n",
    "# execute\n",
    "x_data = np.array([[1, 2, 3]], dtype=theano.config.floatX)\n",
    "for i in range(5):\n",
    "    print('z%d:' % i, f(x_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### given\n",
    "\n",
    "input: transfer from CPU to GPU multiple times\n",
    "* e.g. multiple epochs\n",
    "\n",
    "shared: retained values across functions, can be updated after each function call\n",
    "* like static function variables\n",
    "* not input for function call\n",
    "* e.g. network weights\n",
    "\n",
    "given: transfer from CPU to GPU once\n",
    "* like constant variables\n",
    "* shared between multiple function calls\n",
    "* not input for function call\n",
    "* values specified, for input or shared variables, during funcion compilation \n",
    "* e.g. a mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "If we use `inputs`, a datasets is transferred from the CPU to the GPU multiple times, for example, if we iterate over a dataset multiple times (epochs) during gradient descent. \n",
    "\n",
    "We can use the `givens` variable to insert values into the graph before compiling it. Using this approach we can reduce the number of transfers from RAM (via CPUs) to GPUs to speed up learning with shared variables. \n",
    "\n",
    "Via `givens`, we can keep the dataset on the GPU if it fits (e.g., a mini-batch). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "4.0\n",
      "9.0\n",
      "16.0\n",
      "25.0\n",
      "36.0\n",
      "49.0\n",
      "64.0\n",
      "81.0\n"
     ]
    }
   ],
   "source": [
    "# define\n",
    "num_samples = 10\n",
    "samples = np.asarray([i for i in range(num_samples)],\n",
    "                     dtype=theano.config.floatX)\n",
    "\n",
    "# samples = theano.shared(samples)\n",
    "\n",
    "x = T.lscalar(name='index')\n",
    "#y = theano.shared(np.asscalar(np.array([1], dtype=theano.config.floatX)))\n",
    "y = T.vector(name='samples')\n",
    "w = theano.shared(np.asscalar(np.array([0], dtype=theano.config.floatX)))\n",
    "\n",
    "z = y[x]*w\n",
    "\n",
    "# compile\n",
    "f = theano.function(inputs = [x],\n",
    "                    updates = [[w, w+1]],\n",
    "                    givens = {y: samples},\n",
    "                    outputs = z)\n",
    "\n",
    "# run\n",
    "for i in range(np.prod(samples.shape)):\n",
    "    print(f(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: [[ 3.  5.  7.]]\n",
      "z: [[  9.  11.  13.]]\n",
      "z: [[ 15.  17.  19.]]\n",
      "z: [[ 21.  23.  25.]]\n",
      "z: [[ 27.  29.  31.]]\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "x_data = np.array([[1, 2, 3]], dtype=theano.config.floatX)\n",
    "\n",
    "x = T.matrix(name='hi')\n",
    "w = theano.shared(np.asarray([[0.0, 0.0, 0.0]], dtype=theano.config.floatX))\n",
    "\n",
    "# an input variable can be given\n",
    "b_data = np.array([[-1, 0, 1]], dtype=theano.config.floatX)\n",
    "b = T.matrix(name='bias')\n",
    "\n",
    "# a shared variable can be given\n",
    "c_data = np.array([[4, 5, 6]], dtype=theano.config.floatX)\n",
    "c = theano.shared(np.asarray([[0]], dtype=theano.config.floatX))\n",
    "\n",
    "z = x.dot(w.T) + b + c\n",
    "\n",
    "updates = [[w, w + 1.0]]\n",
    "givens = {b: b_data, c: c_data}\n",
    "\n",
    "# compile\n",
    "net_input = theano.function(inputs=[x], \n",
    "                            updates=updates, \n",
    "                            givens=givens,\n",
    "                            outputs=z)\n",
    "\n",
    "# execute\n",
    "for i in range(5):\n",
    "    print('z:', net_input(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wrapping things up: A  linear regression example\n",
    "\n",
    "Model:\n",
    "$\n",
    "y = \\sum_{i=0}^n w_i x_i = \\mathbf{w}^T \\mathbf{x}\n",
    "$\n",
    "with $x_0 = 1$.\n",
    "\n",
    "Given a collection of sample data $\\{\\mathbf{x^{(i)}}, y^{(i)} \\}$, find the line $\\mathbf{w}$ that minimizes the regression error:\n",
    "$$\n",
    "\\begin{align}\n",
    "L(X, Y, \\mathbf{w}) \n",
    "= \\sum_i \\left( y^{(i)} - \\hat{y}^{(i)} \\right)^2 \n",
    "= \\sum_i \\left( y^{(i)} - \\mathbf{w}^T \\mathbf{x}^{(i)} \\right)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "### 2D case\n",
    "\n",
    "$\n",
    "y = w_0 + w_1 x\n",
    "$\n",
    "\n",
    "<img src='./images/10_01.png' width=90%> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray([[0.0], [1.0], [2.0], [3.0], [4.0],\n",
    "                      [5.0], [6.0], [7.0], [8.0], [9.0]], \n",
    "                     dtype=theano.config.floatX)\n",
    "\n",
    "y_train = np.asarray([1.0, 1.3, 3.1, 2.0, 5.0, \n",
    "                      6.3, 6.6, 7.4, 8.0, 9.0], \n",
    "                     dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Implement the training function\n",
    "\n",
    "Notice:\n",
    "* the symbolic differentiation for the gradient part\n",
    "* how different variable types (input, shared, givens, output) are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "\n",
    "def train_linreg(X_train, y_train, eta, epochs):\n",
    "\n",
    "    costs = []\n",
    "    # Initialize arrays\n",
    "    eta0 = T.scalar('eta0') # learning rate\n",
    "    y = T.vector(name='y') \n",
    "    X = T.matrix(name='X')   \n",
    "    w = theano.shared(np.zeros(\n",
    "                      shape=(X_train.shape[1] + 1),\n",
    "                      dtype=theano.config.floatX),\n",
    "                      name='w')\n",
    "    \n",
    "    # calculate cost\n",
    "    y_pred = T.dot(X, w[1:]) + w[0]\n",
    "    errors = y - y_pred\n",
    "    cost = T.sum(T.pow(errors, 2)) \n",
    "\n",
    "    # perform gradient update\n",
    "    gradient = T.grad(cost, wrt=w) # symbolic differentialtion\n",
    "    update = [(w, w - eta0 * gradient)]\n",
    "\n",
    "    # compile model\n",
    "    train = theano.function(inputs=[eta0],\n",
    "                            outputs=cost,\n",
    "                            updates=update,\n",
    "                            givens={X: X_train,\n",
    "                                    y: y_train})      \n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        # since eta is input\n",
    "        # we can gradually change the learning rate\n",
    "        costs.append(train(eta))\n",
    "    \n",
    "    return costs, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Plotting the sum of squared errors cost vs epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dbc4b7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "costs, w = train_linreg(X_train, y_train, eta=0.001, epochs=10)\n",
    "   \n",
    "plt.plot(range(1, len(costs)+1), costs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/cost_convergence.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xtw1Od97/H3VxLLVQJh8wODDDYXGwzGd5DBmDVXAdJy\n5nTOadIcN5fG06ldx9MkPk3TmYqmPWfSzOm0mZN6Jokdtz0naXLqZsYrIRA3C2zjC9jmYsAGGZub\ngZW4SQgkdHnOHxIbFiwJhHZ/v939vGY0Xj2sVt8dyfru8/ye57PmnENERCSIcvwuQEREpDtqUiIi\nElhqUiIiElhqUiIiElhqUiIiElhqUiIiElgpaVJm9pKZnTSzXVeMFZrZOjP72MyqzWx4KmoREZH0\nkaqZ1MvA0qvGvgdscM7dDWwC/iJFtYiISJqwVB3mNbMJQIVzbmbX5x8B851zJ81sDFDjnJuakmJE\nRCQt+HlNynPOnQRwzp0APB9rERGRAArSxgnlM4mISII8H7/3STMbfcVyX6y7O5qZGpiISAZwztmN\n3D+VMynr+rgsCnyt6/ZXgVd7+mLnXNZ9lJeX+16Dnreet56znnd/ffRFqrag/wrYCtxlZofN7OvA\nD4HFZvYxsLDrcxERkbiULPc55/6gm39alIrvLyIi6SlIGyfkKuFw2O8SfKHnnT2y8TlD9j7vvkjZ\nOambYWYuHeoUEZHumRkuwBsnREREboialIiIBJaalIhIFrl48aLfJdwQNSkRkSxw8eJFvvrVr7J8\n+XKef/552tra/C7puqhJiYhkuEOHDvH7v//7DBs2jHA4zIULF/jrv/5rv8u6Ln7GIomISBK1tLSw\nYcMGtm/fTkNDA57XmePteR4HDx70ubrroyYlIpKBDhw4QGVlJQ0NDQCEQiFisRie51FfX8/48eN9\nrvD66JyUiEgGuXDhAtXV1ezatSthfNKkSezevZtYLEZRURHl5eXk5aV2ntKXc1KaSYmIZADnHHv3\n7qWqqooLFy7Ex4cMGUJJSQkzZszA7Ib6QyBoJiUikuYaGxupqqrio48+Shi/9957+ZM/eZZY7PNu\nvzY/v5CGhtPJLhHo20xKTUpEJE0559ixYwfV1dW0tLTEx/Pz81mxYgV333131+ypp7+f1ue30bhR\nWu4TEckSZ86cobKy8ppdeg8++CCLFy9m0KBBPlXWv9SkRETSSEdHB9u2bWPjxo20trbGxwsLCykr\nK+POO+/0sbr+pyYlIpIm6urqiEajHD16ND5mZsyePZsFCxYwYMAAH6tLDjUpEZGAa29v580332TL\nli20t7fHx0eNGkUkEqGoqMjH6pJLTUpEJMCOHz/Oq6++ysmTJ+NjOTk5zJs3j3nz5pGbm+tjdcmn\nJiUiEkCtra1s3ryZrVu3Juy+Gzt2LJFIhNGjR/tYXeqoSYmIBMzhw4eJRqOcOnUqPpaXl8cTTzxB\ncXExOTnXnw2en19IY2P3u77z8wtvqtZk0zkpEZGAaGlpYePGjWzbti1hfMKECUQiEUaOHOlTZf1D\n56RERNJUbW0tlZWVnDt3Lj4WCoVYvHgxDz30UFpGGvUHNSkRER9dvHiR6upqdu7cmTA+ZcoUSktL\nKSgo8KmyYFCTEhHxyeVA2KampvjY4MGDWbZsWdoGwvY3NSkRkRRrbGxkzZo17Nu3L2F8xowZlJSU\nMHToUJ8qCx41KRGRFGltbeXZZ59l//795OXlUVxcTG5ubkIgrCTS7j4RkRQ4e/YsTz31FJ7n4Xke\nsViM2tpannnmGZYsWZIxgbA90e4+EZGAcc7x7rvvsnHjRurq6pgxYwYAnudx6tQpIpGIzxUGm5qU\niEiS1NfXE41GOXLkCNC5pTwWi+F5HvX19UyZMsXnCoNPy30iIv2svb2drVu3snnz5oRA2JEjR3Lw\n4EHOnj1LUVER5eXl5OVlz1whLZf7zOzPgD8COoDdwNedc5f8rUpEpG+OHz9ONBrlxIkT8bGcnBwe\ne+wx5s2bl1VNqT/4OpMys7HAG8BU59wlM/sNsNo5969X3U8zKREJtLa2Nmpqaq4JhL3tttv44Q//\nF59+eqDbr83PL6Sh4XQqyvRVWs6kgFxgqJl1AEOAz32uR0TkhnQXCBsOh3n00Uf54z/+Y6D7F9o9\nBcBmO1+blHPuczP7e+AwcAFY55zb4GdNIiLXq6dA2LKyMm655RafKsscvjYpMxsBrAQmAOeAV8zs\nD5xzv/KzLhGR3igQNjX8Xu5bBBx0zp0GMLPfAnOAa5rUqlWr4rfD4TDhcDg1FYqIXKG7QNjJkydT\nWlrK8OHDfaoseGpqaqipqbmpx/B748Qs4CXgEaAFeBnY5pz7p6vup40TIuK77gJhS0pKuPfee7ud\nPXWO9/Q3zMiGv3Fpt3HCOfeumb0CfAC0dv33Z37WJCJytfPnz1NVVXVNIOz06dNZtmyZAmGTSId5\nRUS64Zxj586dVFdX09zcHB8fNmwYK1asYOrUqdf1OJpJdUq7mZSISFCdPXuWyspKPvnkk4TxBx54\n4IYDYfPzC3vcZp6fX9jnOjOdZlIiIldwzrFt2zY2bNhAa2trfHzEiBGUlZUxceJEH6tLb5pJiYjc\nhKsDYS+bPXs2CxYsIBQK+VRZ9lKTEpGs110g7K233srKlSspKirysbrspiYlIlmhoGAkjY1nrhkf\nM2YMK1eu5LbbbouPKRA2OHRNSkSywtU77PLy2pg/fzNz575JTk5iIGwkEmHMmDE+VJnZdE1KRKRX\nbYwb913Gj99DTo7hXDGQS2trK8uWLePRRx8lJyfH7yKli2ZSIpIVzIxQqIWpU/+Ixx4rwPM8YrEY\ntbW1jBv3JaLR56mvr/e7zIzWl5mUXi6ISFaYNGkSTz/9AoWFR/A8DwDP8zh2bBj//M9fS3ibDQkO\nNSkRyWgXL17k1Vdf5cknn2TEiHOEQiFisRgAJ07Uc/ToPdzgi3tJIS33iUjG2rdvH1VVVZw/fz4+\ndv58iN/+9gitrRdpaCji3LlyOi/PZ0c0kZ+0cUJEhO4DYT/8cDpr1pTQ1DTMp8rkRmkmJSIZwznH\nrl27WLt27TWBsL/85b/xwQfvdfu1+fmFNDScTkWZWasvMyk1KRHJCD0Fwi5evJjBgwf7VJlcpuU+\nEck6lwNhN27cyKVLl+LjCoTNDGpSIpK26uvrqaio4PDhwwnjCoTNHGpSIpJ2Ojo62Lp1KzU1NdcE\nwkYiEW6//XYfq5P+pCYlImnlxIkTRKNRjh8/Hh/Lyclh7ty5PP744wqEzTD6aYpIWmhra2PLli28\n+eabdHR0xMcVCJvZ1KREJGW6e7uMy7rbBn7kyBGi0WhCtl5ubi7hcJg5c+YoEDaDaQu6iKTM1W+X\n8QX3SEh9uHTpEhs3buTdd99NuNf48eOJRCLccsstySlUkkJb0EUkY3zyySdUVlZy9uzZ+FgoFGLR\nokU8/PDDXQ1PMp2alIgEysWLF1m3bh07duxIGJ88eTKlpaUMHz7cp8rED2pSIhIYU6dO5YUXXkgI\nhB08eDBLly5l5syZmj1lIV2TEpGU6e6a1NCh51m+fA3Tp+9NGL/nnntYtmwZw4YpEDYT6JqUiPSq\nrzvsksMxc+YuSkqqGTLkYnx02LBhLF++nGnTpqWoDgkqNSmRLNPZoLpfmWhsTMWSWhujRn2fO+7Y\nzYgR7QwcWAzkAnD//fezZMkSBcIKoOU+kaxzo9vA+1NBwUjOnz/L5MmTWbx4MZ7nEYvFqK2tZdq0\naWzcWMPu3Tt6fyBJS31Z7tMJOBFJmU8/PcBLL73E2LFj8TwPAM/zGDhwID/60Y/UoOQaWu4TkaTr\n6Ojgrbfeoqamhra2NkKhELFYDM/zqKur47777lNiuXwhLfeJZJlUL/d9USBsR0cHhw8fxjnH7bff\nTnl5uYJhs0Ba7u4zs+HAi8AMoAP4hnPuHX+rEpGb1V0g7JgxY1i5cqUCYeW6+N6kgB8DVc65/2Jm\necAQvwsSkZujQFjpL74u95lZAfCBc25SL/fTcp9IP0nmOalLly6xadMm3nkncTFk/PjxlJWVceut\nt/bpcSUzpONy351AvZm9DNwHbAeec85d7PnLRKSvknVQ9+DBg1RUVFwTCLtw4UIeeeQRRRpJn/jd\npPKAB4FnnHPbzewfge8B5VffcdWqVfHb4XCYcDicohJFpCfNzc1UV1dfEwg7adIkSktLGTFihE+V\nid9qamqoqam5qcfwe7lvNPCWc25i1+ePAX/unCu76n5a7hMJoI8++ojVq1cnBMIOGjSIkpISBcLK\nNdJuuc85d9LMjpjZXc65/cBCYG9vXyci/jp//jxr165lz549CeMKhJX+5vs5KTO7j84t6AOAg8DX\nnXPnrrqPZlIiAeCcY/fu3axdu5aLF3936Xjo0KGsWLFCgbDSo77MpHxvUtdDTUrEf+fOnaOyspLa\n2tqEcQXCyvVKu+U+EQk+5xzbt29nw4YNXLp0KT4+fPhwysrKmDSpxxMkIjdFTUpEunXq1CkqKio4\ndOhQwvisWbNYuHCh8vYk6dSkROQaVwfCXnbLLbcQiUQYP368j9VJNlGTEpEEXxQIa2bMnTuX+fPn\nKwhWUkq/bSIC9BwIG4lEuO2223ysTrKVmpSIcPToUaLRKHV1dfGx3Nxc5s+fz5w5c8jNzfWxOslm\nalIiWaqtrY2/+qu/4sMPP6S5uZni4uJ4M7r99tuJRCIKhBXf6ZyUSJb61re+RXt7O57nEYvFqK2t\nZf78+SxatEiBsJIUfTknpTd1Eckyzc3NRKNRdu3ahed5AHieR05ODk8//TSzZs1Sg5LA0HKfSBa5\nMhA2FAoRi8XwPI+6ujoefvhhJZZL4Gi5TyQLNDU1sWbNmoRA2Pb2dvbv308oFGLChAmUl5dre7kk\nlWKRRNJIMt8h97KeAmGXL1/OPffcc1OPL5JsmkmJ+KTzuk9Pv9fGzfzenzt3jtWrV3PgwIGE8fvu\nu4+lS5cqEFZSTjMpEcE5x3vvvcf69euvCYQtLS1l8uTJPlYncmPUpEQySHeBsI888ggLFy5k4MCB\nPlUm0jdqUiIZQIGwkqnUpETS3MmTJ4lGo3z++efxMTNjzpw5hMNh7diTtKbfXpE01dbWxuuvv84b\nb7yhQFjJWGpSImlIgbCSLdSkRHySn19IY2P3u3Hz8wuvGbt06RKvvfYab7/9dsK4AmElU+mclEia\n+PTTT6moqODMmd8dAB4wYAALFy7kkUceISdHUZwSbDonJZKBmpubWbduHR988EHC+MSJEykrK1Pe\nnmQ0NSmRAPv4449ZvXo1jY2N8bFBgwaxZMkS7r//fqWVS8ZTkxIJoC8KhAWYOnUqy5cvJz8/36fK\nRFJLTUokQHoLhJ02bZpmT5JV1KREAqKnQNglS5YwZMgQnyoT8Y+alIjPWltbeeaZZzhw4AADBgyg\nuLiY3NxcCgoKKC0tZcqUKX6XKOIbbUEX8dHp06d56qmnGDNmDJ7nEYvFqK2t5bnnnlMgrGQcbUEX\nSRMdHR28/fbbvPbaa5w6dYqZM2cC4Hkep0+fZvny5T5XKBIMalIiKXZ1IGwoFCIWi+F5HvX19Xq/\nJ5ErBGK5z8xygO3AUedc5Av+Xct9kva6C4S99dZb+eSTTzhz5gxFRUWUl5cruVwyUjov9z0H7AUK\n/C5EJBm6C4R9/PHHmTt3rgJhRbrhe5MysyJgOfA/gG/7XI5Iv2ptbWXTpk288847XLkaUFRURCQS\nYdSoUT5WJxJ8vTYpM3sW+L/OuTO93beP/gF4HhiepMcX8YUCYUVu3vXMpEYD28zsfeAXQHV/XSAy\nsxXASefcDjMLA92uVa5atSp+OxwOEw6H+6MEkX7X3NzM+vXref/99xPGJ06cSGlpKYWF174Fh0gm\nqqmpoaam5qYe47o2TlhnDssS4OvAw8D/A15yzn1yU9/c7H8C/w1oAwYD+cBvnXN/eNX9tHFC0sIX\nBcIOHDiQpUuXKhBWsl5fNk5c9+4+M7uPziZVArwGFAPrnXP//UYL7ebx5wPf0e4+SUdNTU2sXbuW\nDz/8MGFcgbAiv5OU3X1m9hzwh0A98CLwvHOutWvb+AGgX5qUSDpyzvHhhx+ydu1aLly4EB8fOnQo\ny5Yt45577tHsSeQmXM81qZHAf3bOHbpy0DnXYWal/VWIc24zsLm/Hk8k2RoaGli9ejX79+9PGJ85\ncyZLly5VIKxIPwjEYd7eaLlPgsQ5x/vvv8/69etpaWmJjysQVqRn6XyYVyQtnD59moqKCj777LOE\n8YcffphFixYpEFakn6lJiVyHKwNh29ra4uMjR44kEokwYcIEH6sTyVxqUiK9iMViRKNRjh07Fh8z\nMx599FHC4TADBgzwsTqRzKYmJdKN9vZ2Xn/9dV5//fWEQNjRo0cTiUQYO3asj9WJZAc1KZEvcOzY\nMaLRKLFYLD6mQFiR1FOTErlCa2srr732Gm+//bYCYUUCQE1KhM73evrOd77Dnj17yMnJobi4mNzc\nXAYMGMCCBQuYNWuWAmFFfKBzUpL1mpub+eY3v8nw4cPxPI9YLEZtbS1f+cpXKCsrUyCsSD/pyzkp\nvTQU3xUUjMTMuv0oKBiZtO+9f/9+XnjhBY4ePYrneQB4nkd+fj5PPvmkGpSIz7TcJ75rbDwDdD9T\nbmzs/+y7pqYmqqur2b17NwChUIhYLIbnedTX1zNt2jRl7okEgJb7xHedzaCnn6/RXz9/5xx79uxh\nzZo1CYGwAwcO5MiRI1y4cIGioiLKy8vJy9NrOJH+pFgkkR40NDRQVVXFxx9/nDCuQFiR4FKTkoyn\nQFiR9KUmJRlNgbAi6U1NSjJSR0cH77zzDps2bbomELasrIw77rjDv+JE5LqpSUnGUSCsSOZQkxLf\n5ecX9rjNPD//+s4qtbe388Ybb7Bly5aEQFjP81i5cqUCYUXSkLagS0b4okDYnJwcHn/8cR577DEF\nwooEgLagS9ZpbW2lpqaGt956K+Es1bhx44hEIvEUCRFJT2pSkrY+++wzKioqOH36dHxMgbAimUVN\nStJOS0sL69ev57333ksYv/POOxUIK5Jh1KQkrRw4cIDKykoaGhriYwMHDmTJkiU88MADytsTyTBq\nUpIWLly4wNq1a+OBsJfdfffdLF++nIKCAp8qE5FkUpOSQHPOsXfvXqqqqhICYYcMGcKyZcuYPn26\nZk8iGUxNSgKrsbGR1atXKxBWJIupSUngOOf44IMPWLdu3TWBsCtWrOCuu+7ysToRSSU1KQmUM2fO\nUFFRwaeffpow/tBDD7F48WIFwopkGTUpCYSOjg62bt3K3/7t39Lc3EwoFKK4uJhRo0YpEFYkiykW\nSXxXV1dHNBrlN7/5DVOmTMHzPGKxGE1NTfz85z9XIKxIhuhLLJKvR/LNrMjMNpnZHjPbbWbf8rMe\nSa329nY2b97MT3/6U44ePcqlS5fiMUae52FmSW9QBQUjMbNuPwoKRib1+4tIz/xe7msDvu2c22Fm\nw4D3zGydc+4jn+uSJPv888+JRqOcPHkyPjZw4EDq6uoYNWoU9fX1FBUVJb2OxsYzQPez9J7S2UUk\n+XydSTnnTjjndnTdPg/sA8b5WZMkV2trK+vXr+fFF19MaFDjxo3j5ZdfprCwkM8++4wRI0ZQXl7u\nY6UiEgSBuSZlZncANcCMroZ15b/pmlQGOHToENFoNCEQNi8vjwULFjB79mxfAmE7DwL39Ltl6HdP\npH+k7Vt1dC31vQI8d3WDumzVqlXx2+FwmHA4nJLa5Oa1tLSwYcMGtm/fnjB+xx13UFZWxsiRuu4j\nkolqamqoqam5qcfwfSZlZnlAJbDGOffjbu6jmVSaCnogrGZSIqmTrjOpXwB7u2tQkp4uXLhAdXU1\nu3btShi/6667WLFihQJhReS6+DqTMrO5wBZgN50vZx3wfefc2qvup5lUmrgcCLtmzRqampri40EN\nhNVMSiR10m4m5Zx7E8j1swbpP42NjVRVVfHRR4knCO69915KSkoCGQibn1/Y4zbz/Hy9gaKIn3y/\nJnU9NJMKNuccO3bsoLq6OiEQNj8/n9LSUgXCigiQhjMpSX9nzpyhsrKSgwcPJow/9NBDLFq0iEGD\nBvlUmYhkAjUp6ZOOjg62bdvGxo0baW1tjY8XFhZSVlbGnXfe6WN1IpIp1KTkhl0OhD169Gh8zMwo\nLi7miSeeUCCsiPQbNSm5bu3t7bz55pts2bKF9vb2+LjneUQiEcaNU6KViPQvNSkBOtPAO8NWv9ik\nSXfx3e/+WULeXk5ODvPmzWPevHnk5mqTpoj0P+3uE6D780J5ea2Ew5uZM+f1hGy9sWPHsnLlyvhb\na4iI9Ea7+6RfjR9/iEikgltvPcXlwPy8vDyeeOIJiouLfQmEFZHsoiYl1wiFWli0aCOzZm1LGFcg\nrIikmpb7BPjdct+kSR8xbtx3MTtPKBSiuLiYtrbBrFv3H2zbti1QkUYikl76stynJiVAZ7be0qW/\noqnpBaZMmYLnecRiMbZtq+Pjj1+koWG4MuxE5Kb0pUnpokKAFBSMxMy6/SgoSM4y2969e3nmmWe4\n//6dXLp0Kb4ZwvM8TpwYSkODEstFxB+6JhUgnVvAu5+t9BSE2rfv18iaNWvYt28fw4YNAyAUChGL\nxboaVD0NDUX9+j1FRG6ElvsCJFVvG3E5EHbdunU0NzfHxxsaGqioqCAWi1FQUEBDQwPnzp0DOtPA\nGxpOd/eQIiK90jWpNJeKJnX27FkqKiquCYR98MEHWbx4sQJhRSRpdE5KuuWc491331UgrIikFTWp\nLFBXV0dFRQVHjhyJj5kZs2fPZsGCBQqEFZHAUpPKYO3t7WzdupXNmzcnBMKOGjWKSCRCUZE2RYhI\nsKlJZajjx48TjUY5ceJEfOxyIOxjjz1GXp5+9CISfPpLFSD5+YU9bjPPzy/s9TFaW1vZvHkzW7du\nTdhkMXbsWCKRCKNHj+6XWkVEUkG7+zLI4cOHiUajnDp1Kj6mQFgRCQrt7stSLS0tbNy4kW3bEgNh\nJ0yYQCQSUSCsiKQtNak0V1tbS2VlZfzQLXSmRixevJiHHnpIgbAiktbUpNLUxYsXqa6uZufOnQnj\nU6ZMobS0lIIC5e2JSPpTk0pDe/fupaqqiqampvjY4MGDWbZsGTNmzNDsSUQyhppUGrkyEPZKM2bM\noKSkhKFDh/pUmYhIcqhJpQHnHDt37qS6ujohEDY/P58VK1Zw9913+1idiEjyqEkFXHeBsA888ABL\nlixRIKyIZDQ1qYDqLhB2xIgRlJWVMXHiRB+rExFJDTWpADpx4gRPP/00p0+fJhQKUVxcTG5uLsXF\nxTzxxBOEQiG/SxQRSQnfEyfMrAT4Rzrfyv4l59zffcF9siZxoqmpid/7vd9j0qRJeJ5HLBbj2LFj\n/OQnP1EgrIiktb4kTviak2NmOcBPgKXAdODLZjbVz5r8NnToUAYOHIjneQB4nseIESPUoEQkK/kd\n5jYLOOCcO+ScawV+Daz0uSbfTZ8+nVgsBkB9fT233367zxWJiPjD7yY1DjhyxedHu8ay2g9+8ANG\njhzJZ599xogRIygvL/e7JBERX2jjRADl5eXxN3/zN36XISLiO7+b1DFg/BWfF3WNXWPVqlXx2+Fw\nmHA4nMy6RETkJtXU1FBTU3NTj+Hr7j4zywU+BhYCx4F3gS875/Zddb+s2d0nIpKp0u79pJxz7Wb2\np8A6frcFfV8vXyYiIlnC93NS10MzKRGR9Jd256RERER6oiYlIiKBpSYlIiKBpSYlIiKBpSYlIiKB\npSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYl\nIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKB\npSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKBpSYlIiKB5VuTMrMfmdk+M9thZv9hZgV+1SIi\nIsHk50xqHTDdOXc/cAD4Cx9rCaSamhq/S/CFnnf2yMbnDNn7vPvCtyblnNvgnOvo+vRtoMivWoIq\nW3+R9byzRzY+Z8je590XQbkm9Q1gjd9FiIhIsOQl88HNbD0w+sohwAF/6Zyr6LrPXwKtzrlfJbMW\nERFJP+ac8++bm30NeApY4Jxr6eF+/hUpIiL9xjlnN3L/pM6kemJmJcDzwOM9NSi48SclIiKZwbeZ\nlJkdAELAqa6ht51zT/tSjIiIBJKvy30iIiI9Ccruvl5l0+FfMysxs4/MbL+Z/bnf9aSCmRWZ2SYz\n22Nmu83sW37XlEpmlmNm75tZ1O9aUsXMhpvZv3f9f73HzGb7XVMqmNmfmdmHZrbLzH5pZiG/a0oG\nM3vJzE6a2a4rxgrNbJ2ZfWxm1WY2vLfHSZsmRZYc/jWzHOAnwFJgOvBlM5vqb1Up0QZ82zk3HXgU\neCZLnvdlzwF7/S4ixX4MVDnnpgH3Aft8rifpzGws8CzwoHNuJp37Ar7kb1VJ8zKdf8eu9D1gg3Pu\nbmAT1/F3PG2aVBYd/p0FHHDOHXLOtQK/Blb6XFPSOedOOOd2dN0+T+cfrHH+VpUaZlYELAde9LuW\nVOlaCZnnnHsZwDnX5pxr8LmsVMkFhppZHjAE+NznepLCOfcGcOaq4ZXAv3Td/hfgP/X2OGnTpK6S\nyYd/xwFHrvj8KFnyx/oyM7sDuB94x99KUuYf6Nzpmk0XiO8E6s3s5a5lzp+Z2WC/i0o259znwN8D\nh4FjwFnn3AZ/q0opzzl3EjpfmAJeb18QqCZlZuu71mkvf+zu+m/ZFffR4d8MZmbDgFeA57pmVBnN\nzFYAJ7tmkdb1kQ3ygAeBf3LOPQhcoHMpKKOZ2Qg6ZxMTgLHAMDP7A3+r8lWvL8x8Oyf1RZxzi3v6\n967Dv8uBBSkpyB/HgPFXfF7UNZbxupY/XgH+j3PuVb/rSZG5QMTMlgODgXwz+1fn3B/6XFeyHQWO\nOOe2d33+CpANm4QWAQedc6cBzOy3wBwgW150nzSz0c65k2Y2Boj19gWBmkn15IrDv5HeDv+muW3A\nZDOb0LUNSzqNAAABuElEQVTr50tAtuz4+gWw1zn3Y78LSRXn3Pedc+OdcxPp/FlvyoIGRdeSzxEz\nu6traCHZsXHkMFBsZoPMzOh83pm8YeTq1YEo8LWu218Fen0xGqiZVC/+N52Hf9d3/mwz8/Cvc67d\nzP6Uzt2MOcBLzrlM/iUGwMzmAl8BdpvZB3QuA3zfObfW38okib4F/NLMBgAHga/7XE/SOefeNbNX\ngA+A1q7//szfqpLDzH4FhIFbzOwwUA78EPh3M/sGcAj4r70+jg7ziohIUKXNcp+IiGQfNSkREQks\nNSkREQksNSkREQksNSkREQksNSkREQksNSkREQksNSkREQksNSkRH5nZw2a208xCZja0683w7vG7\nLpGgUOKEiM/M7Ad0hssOpjN09e98LkkkMNSkRHzWlV23DbgIzHH6n1IkTst9Iv67FRgG5AODfK5F\nJFA0kxLxmZm9Cvwbne9WO9Y596zPJYkERjq9VYdIxjGzJ4FLzrlfm1kO8KaZhZ1zNT6XJhIImkmJ\niEhg6ZqUiIgElpqUiIgElpqUiIgElpqUiIgElpqUiIgElpqUiIgElpqUiIgElpqUiIgE1v8H3ZOM\na4wELcoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dcaf59cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_linreg(X, w):\n",
    "    Xt = T.matrix(name='X')\n",
    "    y_pred = T.dot(Xt, w[1:]) + w[0]\n",
    "    predict = theano.function(inputs=[Xt], givens={w: w}, outputs=y_pred)\n",
    "    return predict(X)\n",
    "\n",
    "plt.scatter(X_train, y_train, marker='s', s=50)\n",
    "plt.plot(range(X_train.shape[0]), \n",
    "         predict_linreg(X_train, w), \n",
    "         color='gray', \n",
    "         marker='o', \n",
    "         markersize=4, \n",
    "         linewidth=3)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/linreg.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Theano for neural networks\n",
    "\n",
    "Also use Keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing activation functions for feedforward neural networks\n",
    "\n",
    "There are various activation functions for a multi-layer neural networks.\n",
    "* in theory we can use any differential function\n",
    "* in practice we want (1) non-linearity and (2) goood convergence for gradient descent\n",
    "\n",
    "Sigmoid is one we have seen.\n",
    "* mimics biological neurons\n",
    "* converge slowly for deep networks (vanishing gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic function recap\n",
    "\n",
    "The logistic function, often just called \"sigmoid function\" is in fact a special case of a sigmoid function.\n",
    "\n",
    "Linear input $z$:\n",
    "$$\n",
    "\\begin{align}\n",
    "z &=  w_0x_{0} + \\dots + w_mx_{m} \n",
    "\\\\\n",
    "&= \\sum_{j=0}^{m} x_{j}w_{j} \n",
    "\\\\ \n",
    "&= \\mathbf{w}^T\\mathbf{x}\n",
    "\\end{align}\n",
    "$$\n",
    "$w_0$ is the bias term, matching $x_0 = 1$\n",
    "\n",
    "Logistic activation function:\n",
    "\n",
    "$$\\phi_{logistic}(z) = \\frac{1}{1 +  e^{-z}}$$\n",
    "\n",
    "Output range: (0, 1)\n",
    "* probability for the positive class $z > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Concrete example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|x) = 0.707\n"
     ]
    }
   ],
   "source": [
    "# note that first element (X[0] = 1) to denote bias unit\n",
    "\n",
    "X = np.array([[1, 1.4, 1.5]])\n",
    "w = np.array([0.0, 0.2, 0.4])\n",
    "\n",
    "def net_input(X, w):\n",
    "    z = X.dot(w)\n",
    "    return z\n",
    "\n",
    "def logistic(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_activation(X, w):\n",
    "    z = net_input(X, w)\n",
    "    return np.asscalar(logistic(z))\n",
    "\n",
    "print('P(y=1|x) = %.3f' % logistic_activation(X, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiple outputs\n",
    "\n",
    "One-hot encoding for multi-class classification.\n",
    "* $K$ outputs for $K$ classes\n",
    "\n",
    "Logistic activation outputs cannot be directly interpreted as probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "A MLP perceptron with \n",
    "* 3 hidden units + 1 bias unit in the hidden unit \n",
    "* 3 output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      " [[ 0.87653295]\n",
      " [ 0.57688526]\n",
      " [ 0.90114393]]\n"
     ]
    }
   ],
   "source": [
    "# W : array, shape = [n_output_units, n_hidden_units+1]\n",
    "#          Weight matrix for hidden layer -> output layer.\n",
    "# note that first column (A[:][0] = 1) are the bias units\n",
    "W = np.array([[1.1, 1.2, 1.3, 0.5],\n",
    "              [0.1, 0.2, 0.4, 0.1],\n",
    "              [0.2, 0.5, 2.1, 1.9]])\n",
    "\n",
    "# A : array, shape = [n_hidden+1, n_samples]\n",
    "#          Activation of hidden layer.\n",
    "# note that first element (A[0][0] = 1) is for the bias units\n",
    "\n",
    "A = np.array([[1.0], \n",
    "              [0.1], \n",
    "              [0.3], \n",
    "              [0.7]])\n",
    "\n",
    "# Z : array, shape = [n_output_units, n_samples]\n",
    "#          Net input of output layer.\n",
    "\n",
    "Z = W.dot(A) \n",
    "y_probas = logistic(Z)\n",
    "print('Probabilities:\\n', y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The outputs do not sum to 1 and thus are not probabilities.\n",
    "\n",
    "Need normalization for probability\n",
    "* divide all outputs by their summation\n",
    "* softmax which should be applied to z (linear inputs) before logistic activation\n",
    "\n",
    "OK for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class label: 2\n"
     ]
    }
   ],
   "source": [
    "y_class = np.argmax(Z, axis=0)\n",
    "print('predicted class label: %d' % y_class[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Estimating probabilities in multi-class classification via the softmax function\n",
    "\n",
    "The softmax function \n",
    "* is a generalization of the logistic function\n",
    "* allows us to compute meaningful class probabilities in multi-class settings\n",
    "* i.e. multinomial logistic regression\n",
    "\n",
    "$z$: linear input as usual\n",
    "\n",
    "$K$: number of classes\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(y=j|z) =\\phi_{softmax}(z) = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$P(y=j | z)$: probability of class $j$ for input $z$ in range $(0, 1)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z): \n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "def softmax_activation(X, w):\n",
    "    z = net_input(X, w)\n",
    "    return softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      " [[ 0.40386493]\n",
      " [ 0.07756222]\n",
      " [ 0.51857284]]\n"
     ]
    }
   ],
   "source": [
    "y_probas = softmax(Z) # same Z computed above\n",
    "print('Probabilities:\\n', y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The class probabilities sum to 1.\n",
    "\n",
    "The predicted class is the same as logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class = np.argmax(Z, axis=0)\n",
    "y_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Broadening the output spectrum using a hyperbolic tangent\n",
    "\n",
    "Another special case of a sigmoid function, it can be interpreted as a rescaled version of the logistic function.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi_{tanh}(z) = \\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\phi_{tanh}$ is a rescaled version of $\\phi_{logistic}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi_{tanh}(z) = 2 \\phi_{logistic}(z) - 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Output range: (-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    e_p = np.exp(z) \n",
    "    e_m = np.exp(-z)\n",
    "    return (e_p - e_m) / (e_p + e_m)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEbCAYAAACLGcAmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dcbc3b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = np.arange(-5, 5, 0.005)\n",
    "log_act = logistic(z)\n",
    "tanh_act = tanh(z)\n",
    "\n",
    "# alternatives:\n",
    "# from scipy.special import expit\n",
    "# log_act = expit(z)\n",
    "# tanh_act = np.tanh(z)\n",
    "\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.xlabel('net input $z$')\n",
    "plt.ylabel('activation $\\phi(z)$')\n",
    "plt.axhline(1, color='black', linestyle='--')\n",
    "plt.axhline(0.5, color='black', linestyle='--')\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.axhline(-1, color='black', linestyle='--')\n",
    "\n",
    "plt.plot(z, tanh_act, \n",
    "         linewidth=2, \n",
    "         color='black', \n",
    "         label='tanh')\n",
    "plt.plot(z, log_act, \n",
    "         linewidth=2, \n",
    "         color='lightgreen', \n",
    "         label='logistic')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/activation.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Different activation functions\n",
    "\n",
    "<img src='./images/13_05.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training neural networks efficiently using Keras\n",
    "\n",
    "A library (stared in early 2015) to facilitate neural network training.\n",
    "* built on top of Theano\n",
    "* intuitive and popular API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Once you have Theano installed, [Keras](https://github.com/fchollet/keras) can be installed via\n",
    "\n",
    "    pip install Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1) Download the 4 MNIST datasets from http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "- train-images-idx3-ubyte.gz:  training set images (9912422 bytes) \n",
    "- train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) \n",
    "- t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) \n",
    "- t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n",
    "\n",
    "2) Unzip those files\n",
    "\n",
    "3) Copy the unzipped files to a directory `./mnist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Li-Yi: I enhanced the functions below so that we can do everything (including downloading and decompression) inside ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import struct\n",
    "import gzip\n",
    "import numpy as np\n",
    " \n",
    "def open_mnist(full_path):\n",
    "    if full_path.find('.gz') >= 0:\n",
    "        return gzip.open(full_path, 'rb')\n",
    "    else:\n",
    "        return open(full_path, 'rb')\n",
    "        \n",
    "def pick_mnist(path, name, exts):\n",
    "    for ext in exts:\n",
    "        full_path = os.path.join(path, name + ext)\n",
    "        if os.path.isfile(full_path):\n",
    "            return full_path\n",
    "    # none of the exts options works    \n",
    "    return None\n",
    "\n",
    "def load_mnist(path, kind='train', exts=['', '.gz']):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = pick_mnist(path, kind + '-labels-idx1-ubyte', exts)\n",
    "    images_path = pick_mnist(path, kind + '-images-idx3-ubyte', exts)\n",
    "    \n",
    "    with open_mnist(labels_path) as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))        \n",
    "        if(magic != 2049):\n",
    "            raise IOError(str(magic) + ' != ' + str(2049))\n",
    "            \n",
    "        # np.fromfile does not work with gzip open   \n",
    "        # http://stackoverflow.com/questions/15966335/efficient-numpy-fromfile-on-zipped-files\n",
    "        # labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "        content = lbpath.read()    \n",
    "        labels = np.frombuffer(content, dtype=np.uint8)\n",
    "        if(len(labels) != n):\n",
    "            raise IOError(str(len(labels)) + ' != ' + str(n))\n",
    "        \n",
    "    with open_mnist(images_path) as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        if(magic != 2051):\n",
    "            raise IOError(str(magic) + ' != ' + str(2051))\n",
    "            \n",
    "        # images = np.fromfile(imgpath, dtype=np.uint8).reshape(num, rows*cols)\n",
    "        content = imgpath.read()    \n",
    "        images = np.frombuffer(content, dtype=np.uint8).reshape(num, rows*cols)\n",
    "        if(num != len(labels)):\n",
    "            raise IOError(str(num) + ' != ' + str(len(labels)))\n",
    "            \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, columns: 784\n",
      "Rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "mnist_data_folder = os.path.join('..', 'datasets', 'mnist')\n",
    "exts = ['', '.gz'] # for already gunzipped files and not yet gzipped files\n",
    "\n",
    "X_train, y_train = load_mnist(mnist_data_folder, kind='train', exts=exts)\n",
    "print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))\n",
    "\n",
    "X_test, y_test = load_mnist(mnist_data_folder, kind='t10k', exts=exts)\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multi-layer Perceptron in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to run the following code via GPU, you can execute the Python script that was placed in this directory via\n",
    "\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python mnist_keras_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import theano \n",
    "\n",
    "theano.config.floatX = 'float32'\n",
    "X_train = X_train.astype(theano.config.floatX)\n",
    "X_test = X_test.astype(theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### One-hot encoding of the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 labels:  [5 0 4]\n",
      "\n",
      "First 3 labels (one-hot):\n",
      " [[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "print('First 3 labels: ', y_train[:3])\n",
    "\n",
    "y_train_ohe = np_utils.to_categorical(y_train) \n",
    "print('\\nFirst 3 labels (one-hot):\\n', y_train_ohe[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Implement a neural network\n",
    "\n",
    "* fully connected with 2 hidden layers\n",
    "\n",
    "* tanh for hidden layers\n",
    "\n",
    "* softmax for output layer\n",
    "\n",
    "* cross entropy loss function (to match softmax output)\n",
    "\n",
    "* SGD optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 2s - loss: 2.2290 - acc: 0.3593 - val_loss: 2.1094 - val_acc: 0.5343\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 2s - loss: 1.8846 - acc: 0.5302 - val_loss: 1.6060 - val_acc: 0.5582\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 3s - loss: 1.3895 - acc: 0.5913 - val_loss: 1.1680 - val_acc: 0.6757\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 2s - loss: 1.0596 - acc: 0.6944 - val_loss: 0.9003 - val_acc: 0.7732\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.8551 - acc: 0.7725 - val_loss: 0.7276 - val_acc: 0.8312\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.7184 - acc: 0.8174 - val_loss: 0.6157 - val_acc: 0.8593\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.6256 - acc: 0.8457 - val_loss: 0.5373 - val_acc: 0.8797\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.5537 - acc: 0.8652 - val_loss: 0.4674 - val_acc: 0.8955\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.4973 - acc: 0.8779 - val_loss: 0.4276 - val_acc: 0.9020\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.4579 - acc: 0.8868 - val_loss: 0.3785 - val_acc: 0.9108\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.4262 - acc: 0.8911 - val_loss: 0.3553 - val_acc: 0.9112\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.3954 - acc: 0.8976 - val_loss: 0.3417 - val_acc: 0.9107\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.3759 - acc: 0.9010 - val_loss: 0.3239 - val_acc: 0.9158\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.3628 - acc: 0.9024 - val_loss: 0.3037 - val_acc: 0.9217\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.3402 - acc: 0.9086 - val_loss: 0.3036 - val_acc: 0.9215\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.3303 - acc: 0.9105 - val_loss: 0.2864 - val_acc: 0.9212\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.3335 - acc: 0.9080 - val_loss: 0.2875 - val_acc: 0.9202\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.3187 - acc: 0.9118 - val_loss: 0.2840 - val_acc: 0.9222\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.3131 - acc: 0.9141 - val_loss: 0.2588 - val_acc: 0.9308\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.3065 - acc: 0.9151 - val_loss: 0.2605 - val_acc: 0.9315\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2929 - acc: 0.9174 - val_loss: 0.2551 - val_acc: 0.9298\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.2843 - acc: 0.9195 - val_loss: 0.2518 - val_acc: 0.9320\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2788 - acc: 0.9210 - val_loss: 0.2529 - val_acc: 0.9305\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 4s - loss: 0.2712 - acc: 0.9246 - val_loss: 0.2319 - val_acc: 0.9357\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.2673 - acc: 0.9241 - val_loss: 0.2329 - val_acc: 0.9370\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.2620 - acc: 0.9250 - val_loss: 0.2273 - val_acc: 0.9382\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 4s - loss: 0.2603 - acc: 0.9253 - val_loss: 0.2232 - val_acc: 0.9365\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 4s - loss: 0.2527 - acc: 0.9277 - val_loss: 0.2132 - val_acc: 0.9378\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.2456 - acc: 0.9283 - val_loss: 0.2225 - val_acc: 0.9370\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 4s - loss: 0.2476 - acc: 0.9287 - val_loss: 0.2076 - val_acc: 0.9435\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 6s - loss: 0.2462 - acc: 0.9295 - val_loss: 0.2073 - val_acc: 0.9425\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 3s - loss: 0.2434 - acc: 0.9297 - val_loss: 0.2099 - val_acc: 0.9398\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2438 - acc: 0.9288 - val_loss: 0.2063 - val_acc: 0.9440\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 4s - loss: 0.2386 - acc: 0.9302 - val_loss: 0.2129 - val_acc: 0.9378\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2390 - acc: 0.9309 - val_loss: 0.2063 - val_acc: 0.9413\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2335 - acc: 0.9311 - val_loss: 0.2002 - val_acc: 0.9418\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2328 - acc: 0.9315 - val_loss: 0.1999 - val_acc: 0.9437\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2277 - acc: 0.9333 - val_loss: 0.2130 - val_acc: 0.9380\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2330 - acc: 0.9306 - val_loss: 0.2089 - val_acc: 0.9407\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2199 - acc: 0.9344 - val_loss: 0.1945 - val_acc: 0.9452\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2184 - acc: 0.9358 - val_loss: 0.2008 - val_acc: 0.9422\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2218 - acc: 0.9340 - val_loss: 0.1957 - val_acc: 0.9443\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2160 - acc: 0.9357 - val_loss: 0.2013 - val_acc: 0.9432\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2169 - acc: 0.9366 - val_loss: 0.2102 - val_acc: 0.9393\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2177 - acc: 0.9356 - val_loss: 0.1863 - val_acc: 0.9463\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 5s - loss: 0.2096 - acc: 0.9390 - val_loss: 0.1991 - val_acc: 0.9415\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2072 - acc: 0.9406 - val_loss: 0.1892 - val_acc: 0.9483\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2079 - acc: 0.9389 - val_loss: 0.1841 - val_acc: 0.9477\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2102 - acc: 0.9383 - val_loss: 0.1831 - val_acc: 0.9477\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s - loss: 0.2051 - acc: 0.9400 - val_loss: 0.1784 - val_acc: 0.9478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12dcf666a20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "np.random.seed(1) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=X_train.shape[1], \n",
    "                output_dim=50, \n",
    "                init='uniform', \n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(Dense(input_dim=50, \n",
    "                output_dim=50, \n",
    "                init='uniform', \n",
    "                activation='tanh'))\n",
    "\n",
    "model.add(Dense(input_dim=50, \n",
    "                output_dim=y_train_ohe.shape[1], \n",
    "                init='uniform', \n",
    "                activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train_ohe, \n",
    "          nb_epoch=50, \n",
    "          batch_size=300, \n",
    "          verbose=1, \n",
    "          validation_split=0.1 # 10% of training data for validation per epoch\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train, verbose=0)\n",
    "print('First 3 predictions: ', y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 94.15%\n"
     ]
    }
   ],
   "source": [
    "train_acc = np.sum(y_train == y_train_pred, axis=0) / X_train.shape[0]\n",
    "print('Training accuracy: %.2f%%' % (train_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 93.58%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test, verbose=0)\n",
    "test_acc = np.sum(y_test == y_test_pred, axis=0) / X_test.shape[0]\n",
    "print('Test accuracy: %.2f%%' % (test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "Plenty deep learning libraries to use so that we do not have to write code from scratch.\n",
    "* TensorFlow: similar flavor to Theano, developed by Google\n",
    "* Torch7: via lua language, used by DeepMind folks and Yann LeCun\n",
    "* Caffe: c++ library\n",
    "* etc.\n",
    "\n",
    "Alternative libraries with Theano:\n",
    "* Pylearn2\n",
    "* Lasagne: more minimalistic and extensible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading\n",
    "\n",
    "* PML Chapter 13"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
